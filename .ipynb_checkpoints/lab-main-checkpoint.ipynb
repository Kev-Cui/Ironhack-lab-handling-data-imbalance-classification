{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4a5329",
   "metadata": {},
   "source": [
    "# Lab | Handling Data Imbalance in Classification Models\n",
    "\n",
    "For this lab and in the next lessons we will use the dataset 'Healthcare For All' building a model to predict who will donate (TargetB) and then - how much they will give (TargetD) (will be used for lab on Friday). You will be using `files_for_lab/categorical.csv, numerical.csv, and target.csv` which can be found at this link.\n",
    "[link to data](https://github.com/ta-data-remote/lab-random-forests/tree/master/files_for_lab)\n",
    "You will need to download the data locally.  Remember to add the files to your .gitignore.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You are revisiting the Healthcare for All Case Study. You are provided with this historical data about Donors and how much they donated. Your task is to build a machine learning model that will help the company identify people who are more likely to donate and then try to predict the donation amount.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "In this lab, we will take a look at the degree of imbalance in the data and correct it using the techniques we learned in the class.  You should fork and clone this Repo and begin a new Jupyter notebook.\n",
    "\n",
    "Here are the steps to be followed (building a simple model without balancing the data):\n",
    "\n",
    "\n",
    "**Everyone is starting with the same cleaned data**\n",
    "\n",
    " \n",
    "\n",
    "**Begin the Modeling here**\n",
    "- Look critically at the dtypes of numerical and categorical columns and make changes where appropriate.\n",
    "- Concatenate numerical and categorical back together again for your X dataframe.  Designate the TargetB as y.\n",
    "  - Split the data into a training set and a test set.\n",
    "  - Split further into train_num and train_cat.  Also test_num and test_cat.\n",
    "  - Scale the features either by using MinMax Scaler or a Standard Scaler. (train_num, test_num)\n",
    "  - Encode the categorical features using One-Hot Encoding or Ordinal Encoding.  (train_cat, test_cat)\n",
    "      - **fit** only on train data, transform both train and test\n",
    "      - again re-concatenate train_num and train_cat as X_train as well as test_num and test_cat as X_test\n",
    "  - Fit a logistic regression (classification) model on the training data.\n",
    "  - Check the accuracy on the test data.\n",
    "\n",
    "**Note**: So far we have not balanced the data.\n",
    "\n",
    "Managing imbalance in the dataset\n",
    "\n",
    "- Check for the imbalance.\n",
    "- Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes.\n",
    "- Each time fit the model and see how the accuracy of the model has changed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b049fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21b7da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = pd.read_csv('numerical.csv')\n",
    "cat = pd.read_csv('categorical.csv')\n",
    "tgt = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f7af1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCODE         int64\n",
       "AGE         float64\n",
       "INCOME        int64\n",
       "WEALTH1       int64\n",
       "HIT           int64\n",
       "             ...   \n",
       "AVGGIFT     float64\n",
       "CONTROLN      int64\n",
       "HPHONE_D      int64\n",
       "RFA_2F        int64\n",
       "CLUSTER2      int64\n",
       "Length: 315, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.isna().sum().sum() # no null values\n",
    "num.dtypes # why do we still have 315 columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21de734c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cat.isna().sum().sum() # no null values\n",
    "# print(cat.dtypes) # a lot of columns with value type int64, after reviewing, I don't think any of these are ordinal values, \n",
    "#                   # thus I'll simply change them all to objects\n",
    "# cat = cat.astype(str)\n",
    "# print(cat.dtypes)\n",
    "\n",
    "#Note from friday: Nope, don't do this, cause tremendous problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51e1aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat as X, assign target as y; split to train/test, and further split to num/cat _ train/test\n",
    "X = pd.concat([num,cat],axis=1)\n",
    "y = tgt['TARGET_B']\n",
    "\n",
    "# splitting into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# further split\n",
    "train_num = X_train.select_dtypes('number')\n",
    "test_num = X_test.select_dtypes('number')\n",
    "train_cat = X_train.select_dtypes(exclude='number')\n",
    "test_cat = X_test.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc08af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer = MinMaxScaler().fit(train_num)\n",
    "\n",
    "train_num = pd.DataFrame(transformer.transform(train_num), columns=train_num.columns)\n",
    "test_num = pd.DataFrame(transformer.transform(test_num), columns=train_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ff1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encode categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder().fit(train_cat)\n",
    "\n",
    "train_cat = pd.DataFrame(encoder.transform(train_cat).toarray(), columns=encoder.get_feature_names_out())\n",
    "test_cat = pd.DataFrame(encoder.transform(test_cat).toarray(), columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d41b6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconcat transformed and encoded dataframes back into X_train and X_test\n",
    "X_train = pd.concat([train_num,train_cat],axis=1)\n",
    "X_test = pd.concat([test_num,test_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e63ca327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951055913640413"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classification = LogisticRegression(random_state=7, solver='saga',\n",
    "                  multi_class='multinomial', max_iter=1000).fit(X_train, y_train)\n",
    "classification.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9ec82f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9492411855951033"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score: 0.95 <-- Hey, that's pretty good! But are we just simply predicting the majority here?\n",
    "tgt['TARGET_B'].value_counts()[0]/len(tgt) # Aparrently the majority consist of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57e4e72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18149,     0],\n",
       "       [  934,     0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred) # it's all zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cac09c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144840, 361)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample with SMOTE, I like SMOTE because I just like the feeling of trusting blackboxes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=7, k_neighbors=3)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train,y_train)\n",
    "X_train_SMOTE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a98fc12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6028926269454489\n",
      "precision:  0.06654488517745302\n",
      "recall:  0.5460385438972163\n",
      "f1:  0.11863224005582693\n"
     ]
    }
   ],
   "source": [
    "# LR again but with different variable name to keep the difference\n",
    "LR = LogisticRegression(random_state=7, solver='saga',\n",
    "                  multi_class='multinomial', max_iter=1000)\n",
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred = LR.predict(X_test)\n",
    "\n",
    "print(\"accuracy: \", LR.score(X_test, y_test))\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh no! accuracy has dropped significantly. But recall as increased by a lot, resulting in f1 score increase as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ae029",
   "metadata": {},
   "source": [
    "# Lab | Random Forests\n",
    "\n",
    "For this lab, you will be using the .CSV files provided in the `files_for_lab` folder.  These are cleaned versions of the learningSet data from the Case Study 'Healthcare for All'.   \n",
    "You may continue in the Jupyter Notebook you created yesterday.  There is no need to fork and clone this Repo.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Apply the Random Forests algorithm AFTER upscaling the data to deal with the imbalance.\n",
    "- Use Feature Selections that you have learned in class to decide if you want to use all of the features (Variance Threshold, RFE, PCA, etc.)\n",
    "- Re-run the Random Forest algorithm to determine if the Feature Selection has improved the results.\n",
    "- Discuss the output and its impact in the business scenario. Is the cost of a false positive equals to the cost of the false negative? How would you change your algorithm or data in order to maximize the return of the business?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59980468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958733775200221\n",
      "0.9232825027511398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, # max number of questions to ask\n",
    "                             min_samples_split=20, # amount of rows still considered at every question\n",
    "                             min_samples_leaf =20, # ultimate answer based on at least this many rows\n",
    "                             max_samples=0.8, # fraction of X-train to use in each tree\n",
    "                             random_state=7)\n",
    "clf.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "print(clf.score(X_train_SMOTE, y_train_SMOTE))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cac9ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.06557377049180328\n",
      "recall:  0.042826552462526764\n",
      "f1:  0.05181347150259067\n"
     ]
    }
   ],
   "source": [
    "# accuracy is not bad, much better than the Logistic Regression model\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb774241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None of the above three metrics are better than the Logistic Regression model\n",
    "# Let's use PCA to build/reduce features\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(0.80).fit(X_train_SMOTE)\n",
    "# pca.explained_variance_ratio_ # OK this looks cool, acceptable number of features adding up to explained variance ratio of 0.90\n",
    "#                               # But even the one with highest evr is not too high (0.09), I'll try anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84084e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_SMOTE_pca = pca.transform(X_train_SMOTE)\n",
    "\n",
    "# clf2 = RandomForestClassifier(max_depth=10, # max number of questions to ask\n",
    "#                              min_samples_split=20, # amount of rows still considered at every question\n",
    "#                              min_samples_leaf =20, # ultimate answer based on at least this many rows\n",
    "#                              random_state=7)\n",
    "# clf2.fit(X_train_SMOTE_pca, y_train_SMOTE)\n",
    "\n",
    "# pred2 = clf2.predict(pca.transform(X_test))\n",
    "\n",
    "# print(\"accuracy: \",clf2.score(pca.transform(X_test), y_test))\n",
    "# print(\"precision: \",precision_score(y_test,pred2))\n",
    "# print(\"recall: \",recall_score(y_test,pred2))\n",
    "# print(\"f1: \",f1_score(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f76ec713",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# this forest has way better recall and f1 score than the previous before pca\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 3\u001b[0m confusion_matrix(y_test,pred2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred2' is not defined"
     ]
    }
   ],
   "source": [
    "# this forest has way better recall and f1 score than the previous before pca\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86219711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would just use the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbc76b",
   "metadata": {},
   "source": [
    "# Lab | Final regression model in \"Health Care for All\" Case\n",
    "\n",
    "### Instructions\n",
    "\n",
    "At this point, we have created a model to predict who will make a donation and who won't (Classification Model). But, what about the ammount of money that each person will give?\n",
    "\n",
    "In this lab, subset those that have made a donation (Target B) and use that subset to create a model to predict how much money will they give (Target D) (Regression Model).\n",
    "\n",
    "- Only look at people who have donated (Target B = 1)\n",
    "- Use this new dataframe to create a model to predict how much they will donate (Target D)\n",
    "- Using the regression model, make predictions on all of the people our classification model predicted will donate.\n",
    "- See the pdf file for a schema of the process.\n",
    "\n",
    "Evaluate the result of your model and estimate how much better the result are for the business in comparison with the naive scenario we discuss on Monday. (Just sending donation cards to everyone)\n",
    "\n",
    "You can see a flowchart for the project here --  [Lucid Flowchart](https://lucid.app/lucidchart/dd701870-3d4e-45c3-b49c-01976181ae06/edit?viewport_loc=-15%2C-25%2C2150%2C1048%2C0_0&invitationId=inv_089ae862-550b-4e82-a606-a8122f39d2f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef33e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 339)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat all data to a big dataframe\n",
    "all_data = pd.concat([num,cat,tgt],axis=1)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be233c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select X and y, and train-test-split for regression model\n",
    "donations_data = all_data[all_data['TARGET_B']==1]\n",
    "X = donations_data.drop(columns=['TARGET_B','TARGET_D'])\n",
    "y = donations_data['TARGET_D']\n",
    "\n",
    "# splitting into train set and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# further split\n",
    "train_num = X_train.select_dtypes('number')\n",
    "test_num = X_test.select_dtypes('number')\n",
    "train_cat = X_train.select_dtypes(exclude='number')\n",
    "test_cat = X_test.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68fa2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer = MinMaxScaler().fit(train_num)\n",
    "\n",
    "train_num = pd.DataFrame(transformer.transform(train_num), columns=train_num.columns)\n",
    "test_num = pd.DataFrame(transformer.transform(test_num), columns=train_num.columns)\n",
    "\n",
    "# One-Hot-Encode categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder().fit(train_cat)\n",
    "\n",
    "train_cat = pd.DataFrame(encoder.transform(train_cat).toarray(), columns=encoder.get_feature_names_out())\n",
    "test_cat = pd.DataFrame(encoder.transform(test_cat).toarray(), columns=encoder.get_feature_names_out())\n",
    "\n",
    "# reconcat transformed and encoded dataframes back into X_train and X_test\n",
    "X_train = pd.concat([train_num,train_cat],axis=1)\n",
    "X_test = pd.concat([test_num,test_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fbff3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# model1 = DecisionTreeRegressor()\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# model2 = LinearRegression()\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# model3 = KNeighborsRegressor()\n",
    "\n",
    "# model_pipeline = [model1, model2, model3]\n",
    "# model_names = ['Decision Tree Regressor', 'Linear Regression', 'KNN']\n",
    "# scores = {}\n",
    "# for model, model_name in zip(model_pipeline, model_names):\n",
    "#     mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "#     scores[model_name] = mean_score\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b43fe7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2: 0.591708326367602 -- test R2: 0.43991407526510484\n"
     ]
    }
   ],
   "source": [
    "# we will use linear regression\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "\n",
    "linreg=LinReg()    # model\n",
    "linreg.fit(X_train, y_train)   # model training\n",
    "y_pred_linreg=linreg.predict(X_test)   # model prediction\n",
    "\n",
    "print ('train R2: {} -- test R2: {}'.format(linreg.score(X_train, y_train),\n",
    "                                            linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0a9f1",
   "metadata": {},
   "source": [
    "### Now the models are ready, moving onto applying it to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf321b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the input X\n",
    "X = all_data.drop(columns=['TARGET_B','TARGET_D'])\n",
    "\n",
    "numericalX    = X.select_dtypes('number')\n",
    "categoricalX = X.select_dtypes(exclude='number')\n",
    "\n",
    "\n",
    "scaled_numerical_X = transformer.transform(numericalX)\n",
    "scaled_numerical_X = pd.DataFrame(scaled_numerical_X, columns=numericalX.columns)\n",
    "\n",
    "encoded_categorical_X = encoder.transform(categoricalX).toarray()\n",
    "encoded_categorical_X =pd.DataFrame(encoded_categorical_X, columns=encoder.get_feature_names_out())\n",
    "\n",
    "\n",
    "X = pd.concat([scaled_numerical_X, encoded_categorical_X], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49a8ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95412, 361) (95412, 340)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d16c4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Classification\n",
    "X['pred_target_b'] = LR.predict(X) # Using the LogisticRegression model trained with SMOTE data, explained choice above.\n",
    "                                          # Got predictions (we are really over predicting a lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86069422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data and apply regression model\n",
    "X = X[X['pred_target_b'] == 1]\n",
    "\n",
    "#model:\n",
    "X['pred_amount'] = linreg.predict(X.drop(columns=['pred_target_b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6cda8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of predicted donors: 64643 ; sum of predicted amount: 1039892.8515625\n"
     ]
    }
   ],
   "source": [
    "print('number of predicted donors:',X['pred_amount'].count(),'; sum of predicted amount:',X['pred_amount'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58d4427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    64643.000000\n",
       "mean        16.086705\n",
       "std          8.880228\n",
       "min        -60.392578\n",
       "25%         10.379883\n",
       "50%         15.365234\n",
       "75%         19.779297\n",
       "max        322.824219\n",
       "Name: pred_amount, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['pred_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894d7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
