{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4a5329",
   "metadata": {},
   "source": [
    "# Lab | Handling Data Imbalance in Classification Models\n",
    "\n",
    "For this lab and in the next lessons we will use the dataset 'Healthcare For All' building a model to predict who will donate (TargetB) and then - how much they will give (TargetD) (will be used for lab on Friday). You will be using `files_for_lab/categorical.csv, numerical.csv, and target.csv` which can be found at this link.\n",
    "[link to data](https://github.com/ta-data-remote/lab-random-forests/tree/master/files_for_lab)\n",
    "You will need to download the data locally.  Remember to add the files to your .gitignore.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You are revisiting the Healthcare for All Case Study. You are provided with this historical data about Donors and how much they donated. Your task is to build a machine learning model that will help the company identify people who are more likely to donate and then try to predict the donation amount.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "In this lab, we will take a look at the degree of imbalance in the data and correct it using the techniques we learned in the class.  You should fork and clone this Repo and begin a new Jupyter notebook.\n",
    "\n",
    "Here are the steps to be followed (building a simple model without balancing the data):\n",
    "\n",
    "\n",
    "**Everyone is starting with the same cleaned data**\n",
    "\n",
    " \n",
    "\n",
    "**Begin the Modeling here**\n",
    "- Look critically at the dtypes of numerical and categorical columns and make changes where appropriate.\n",
    "- Concatenate numerical and categorical back together again for your X dataframe.  Designate the TargetB as y.\n",
    "  - Split the data into a training set and a test set.\n",
    "  - Split further into train_num and train_cat.  Also test_num and test_cat.\n",
    "  - Scale the features either by using MinMax Scaler or a Standard Scaler. (train_num, test_num)\n",
    "  - Encode the categorical features using One-Hot Encoding or Ordinal Encoding.  (train_cat, test_cat)\n",
    "      - **fit** only on train data, transform both train and test\n",
    "      - again re-concatenate train_num and train_cat as X_train as well as test_num and test_cat as X_test\n",
    "  - Fit a logistic regression (classification) model on the training data.\n",
    "  - Check the accuracy on the test data.\n",
    "\n",
    "**Note**: So far we have not balanced the data.\n",
    "\n",
    "Managing imbalance in the dataset\n",
    "\n",
    "- Check for the imbalance.\n",
    "- Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes.\n",
    "- Each time fit the model and see how the accuracy of the model has changed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b049fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b7da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = pd.read_csv('numerical.csv')\n",
    "cat = pd.read_csv('categorical.csv')\n",
    "tgt = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7af1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCODE         int64\n",
       "AGE         float64\n",
       "INCOME        int64\n",
       "WEALTH1       int64\n",
       "HIT           int64\n",
       "             ...   \n",
       "AVGGIFT     float64\n",
       "CONTROLN      int64\n",
       "HPHONE_D      int64\n",
       "RFA_2F        int64\n",
       "CLUSTER2      int64\n",
       "Length: 315, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.isna().sum().sum() # no null values\n",
    "num.dtypes # why do we still have 315 columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21de734c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE           object\n",
      "CLUSTER          int64\n",
      "HOMEOWNR        object\n",
      "GENDER          object\n",
      "DATASRCE         int64\n",
      "RFA_2R          object\n",
      "RFA_2A          object\n",
      "GEOCODE2        object\n",
      "DOMAIN_A        object\n",
      "DOMAIN_B         int64\n",
      "ODATEW_YR        int64\n",
      "ODATEW_MM        int64\n",
      "DOB_YR           int64\n",
      "DOB_MM           int64\n",
      "MINRDATE_YR      int64\n",
      "MINRDATE_MM      int64\n",
      "MAXRDATE_YR      int64\n",
      "MAXRDATE_MM      int64\n",
      "LASTDATE_YR      int64\n",
      "LASTDATE_MM      int64\n",
      "FIRSTDATE_YR     int64\n",
      "FIRSTDATE_MM     int64\n",
      "dtype: object\n",
      "STATE           object\n",
      "CLUSTER         object\n",
      "HOMEOWNR        object\n",
      "GENDER          object\n",
      "DATASRCE        object\n",
      "RFA_2R          object\n",
      "RFA_2A          object\n",
      "GEOCODE2        object\n",
      "DOMAIN_A        object\n",
      "DOMAIN_B        object\n",
      "ODATEW_YR       object\n",
      "ODATEW_MM       object\n",
      "DOB_YR          object\n",
      "DOB_MM          object\n",
      "MINRDATE_YR     object\n",
      "MINRDATE_MM     object\n",
      "MAXRDATE_YR     object\n",
      "MAXRDATE_MM     object\n",
      "LASTDATE_YR     object\n",
      "LASTDATE_MM     object\n",
      "FIRSTDATE_YR    object\n",
      "FIRSTDATE_MM    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cat.isna().sum().sum() # no null values\n",
    "print(cat.dtypes) # a lot of columns with value type int64, after reviewing, I don't think any of these are ordinal values, \n",
    "                  # thus I'll simply change them all to objects\n",
    "cat = cat.astype(str)\n",
    "print(cat.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e1aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat as X, assign target as y; split to train/test, and further split to num/cat _ train/test\n",
    "X = pd.concat([num,cat],axis=1)\n",
    "y = tgt['TARGET_B']\n",
    "\n",
    "# splitting into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# further split\n",
    "train_num = X_train.select_dtypes('number')\n",
    "test_num = X_test.select_dtypes('number')\n",
    "train_cat = X_train.select_dtypes(exclude='number')\n",
    "test_cat = X_test.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc08af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer = MinMaxScaler().fit(train_num)\n",
    "\n",
    "train_num = pd.DataFrame(transformer.transform(train_num), columns=train_num.columns)\n",
    "test_num = pd.DataFrame(transformer.transform(test_num), columns=train_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ff1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encode categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder().fit(cat) # used whole cat here: my train_test_split (random_state = 7) gave me an value in test_cat that was unseen in train_cat. So I've decided to violate the integrity of my process\n",
    "cols = [colname for row in encoder.categories_ for colname in row]\n",
    "\n",
    "train_cat = pd.DataFrame(encoder.transform(train_cat).toarray(), columns=cols)\n",
    "test_cat = pd.DataFrame(encoder.transform(test_cat).toarray(), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41b6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconcat transformed and encoded dataframes back into X_train and X_test\n",
    "X_train = pd.concat([train_num,train_cat],axis=1)\n",
    "X_test = pd.concat([test_num,test_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63ca327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509511083163025"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classification = LogisticRegression(random_state=7, solver='lbfgs',\n",
    "                  multi_class='multinomial', max_iter=1000).fit(X_train, y_train)\n",
    "classification.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ec82f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9492411855951033"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score: 0.95 <-- Hey, that's pretty good! But are we just simply predicting the majority here?\n",
    "tgt['TARGET_B'].value_counts()[0]/len(tgt) # Aparrently the majority consist of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "545834ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.25\n",
      "recall:  0.0010706638115631692\n",
      "f1:  0.0021321961620469083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred = classification.predict(X_test)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e4e72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18146,     3],\n",
       "       [  933,     1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac09c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144840, 656)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample with SMOTE, I like SMOTE because I just like the feeling of trusting blackboxes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=7, k_neighbors=3)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train,y_train)\n",
    "X_train_SMOTE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98fc12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6156788764869255\n",
      "precision:  0.06616052060737528\n",
      "recall:  0.5224839400428265\n",
      "f1:  0.1174488567990373\n"
     ]
    }
   ],
   "source": [
    "# LR again but with different variable name to keep the difference\n",
    "LR = LogisticRegression(random_state=7, solver='saga',\n",
    "                  multi_class='multinomial', max_iter=1000)\n",
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred = LR.predict(X_test)\n",
    "\n",
    "print(\"accuracy: \", LR.score(X_test, y_test))\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe91350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh no! accuracy and precision has dropped significantly. But recall as increased by a lot, resulting in f1 score increase as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f32cb",
   "metadata": {},
   "source": [
    "# Lab | Random Forests\n",
    "\n",
    "For this lab, you will be using the .CSV files provided in the `files_for_lab` folder.  These are cleaned versions of the learningSet data from the Case Study 'Healthcare for All'.   \n",
    "You may continue in the Jupyter Notebook you created yesterday.  There is no need to fork and clone this Repo.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Apply the Random Forests algorithm AFTER upscaling the data to deal with the imbalance.\n",
    "- Use Feature Selections that you have learned in class to decide if you want to use all of the features (Variance Threshold, RFE, PCA, etc.)\n",
    "- Re-run the Random Forest algorithm to determine if the Feature Selection has improved the results.\n",
    "- Discuss the output and its impact in the business scenario. Is the cost of a false positive equals to the cost of the false negative? How would you change your algorithm or data in order to maximize the return of the business?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91af696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9743233913283623\n",
      "0.9503222763716397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=20, # max number of questions to ask\n",
    "                             min_samples_split=20, # amount of rows still considered at every question\n",
    "                             min_samples_leaf =20, # ultimate answer based on at least this many rows\n",
    "                             max_samples=0.8, # fraction of X-train to use in each tree\n",
    "                             random_state=7)\n",
    "clf.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "print(clf.score(X_train_SMOTE, y_train_SMOTE))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77e5dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.1111111111111111\n",
      "recall:  0.0021413276231263384\n",
      "f1:  0.004201680672268908\n"
     ]
    }
   ],
   "source": [
    "# accuracy is not bad, much better than the Logistic Regression model\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8887a9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09689771, 0.04342327, 0.03896155])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None of the above three metrics are better than the Logistic Regression model\n",
    "# Let's use PCA to build/reduce features\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.80).fit(X_train_SMOTE)\n",
    "pca.explained_variance_ratio_ # OK this looks cool, acceptable number of features adding up to explained variance ratio of 0.90\n",
    "                              # But even the one with highest evr is not too high (0.09), I'll try anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "097b4a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7328512288424252\n",
      "precision:  0.058524173027989825\n",
      "recall:  0.2955032119914347\n",
      "f1:  0.09769911504424779\n"
     ]
    }
   ],
   "source": [
    "X_train_SMOTE_pca = pca.transform(X_train_SMOTE)\n",
    "\n",
    "clf2 = RandomForestClassifier(max_depth=10, # max number of questions to ask\n",
    "                             min_samples_split=20, # amount of rows still considered at every question\n",
    "                             min_samples_leaf =20, # ultimate answer based on at least this many rows\n",
    "                             random_state=7)\n",
    "clf2.fit(X_train_SMOTE_pca, y_train_SMOTE)\n",
    "\n",
    "pred2 = clf2.predict(pca.transform(X_test))\n",
    "\n",
    "print(\"accuracy: \",clf2.score(pca.transform(X_test), y_test))\n",
    "print(\"precision: \",precision_score(y_test,pred2))\n",
    "print(\"recall: \",recall_score(y_test,pred2))\n",
    "print(\"f1: \",f1_score(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c264bd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13709,  4440],\n",
       "       [  658,   276]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this forest has way better recall and f1 score than the previous before pca\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would just use the logistic regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
