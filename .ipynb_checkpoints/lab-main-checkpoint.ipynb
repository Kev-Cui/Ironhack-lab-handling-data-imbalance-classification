{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e530d57",
   "metadata": {},
   "source": [
    "# Lab | Handling Data Imbalance in Classification Models\n",
    "\n",
    "For this lab and in the next lessons we will use the dataset 'Healthcare For All' building a model to predict who will donate (TargetB) and then - how much they will give (TargetD) (will be used for lab on Friday). You will be using `files_for_lab/categorical.csv, numerical.csv, and target.csv` which can be found at this link.\n",
    "[link to data](https://github.com/ta-data-remote/lab-random-forests/tree/master/files_for_lab)\n",
    "You will need to download the data locally.  Remember to add the files to your .gitignore.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You are revisiting the Healthcare for All Case Study. You are provided with this historical data about Donors and how much they donated. Your task is to build a machine learning model that will help the company identify people who are more likely to donate and then try to predict the donation amount.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "In this lab, we will take a look at the degree of imbalance in the data and correct it using the techniques we learned in the class.  You should fork and clone this Repo and begin a new Jupyter notebook.\n",
    "\n",
    "Here are the steps to be followed (building a simple model without balancing the data):\n",
    "\n",
    "\n",
    "**Everyone is starting with the same cleaned data**\n",
    "\n",
    " \n",
    "\n",
    "**Begin the Modeling here**\n",
    "- Look critically at the dtypes of numerical and categorical columns and make changes where appropriate.\n",
    "- Concatenate numerical and categorical back together again for your X dataframe.  Designate the TargetB as y.\n",
    "  - Split the data into a training set and a test set.\n",
    "  - Split further into train_num and train_cat.  Also test_num and test_cat.\n",
    "  - Scale the features either by using MinMax Scaler or a Standard Scaler. (train_num, test_num)\n",
    "  - Encode the categorical features using One-Hot Encoding or Ordinal Encoding.  (train_cat, test_cat)\n",
    "      - **fit** only on train data, transform both train and test\n",
    "      - again re-concatenate train_num and train_cat as X_train as well as test_num and test_cat as X_test\n",
    "  - Fit a logistic regression (classification) model on the training data.\n",
    "  - Check the accuracy on the test data.\n",
    "\n",
    "**Note**: So far we have not balanced the data.\n",
    "\n",
    "Managing imbalance in the dataset\n",
    "\n",
    "- Check for the imbalance.\n",
    "- Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes.\n",
    "- Each time fit the model and see how the accuracy of the model has changed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e86d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "121707c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = pd.read_csv('numerical.csv')\n",
    "cat = pd.read_csv('categorical.csv')\n",
    "tgt = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07fa951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCODE         int64\n",
       "AGE         float64\n",
       "INCOME        int64\n",
       "WEALTH1       int64\n",
       "HIT           int64\n",
       "             ...   \n",
       "AVGGIFT     float64\n",
       "CONTROLN      int64\n",
       "HPHONE_D      int64\n",
       "RFA_2F        int64\n",
       "CLUSTER2      int64\n",
       "Length: 315, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.isna().sum().sum() # no null values\n",
    "num.dtypes # why do we still have 315 columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d92acab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE           object\n",
      "CLUSTER          int64\n",
      "HOMEOWNR        object\n",
      "GENDER          object\n",
      "DATASRCE         int64\n",
      "RFA_2R          object\n",
      "RFA_2A          object\n",
      "GEOCODE2        object\n",
      "DOMAIN_A        object\n",
      "DOMAIN_B         int64\n",
      "ODATEW_YR        int64\n",
      "ODATEW_MM        int64\n",
      "DOB_YR           int64\n",
      "DOB_MM           int64\n",
      "MINRDATE_YR      int64\n",
      "MINRDATE_MM      int64\n",
      "MAXRDATE_YR      int64\n",
      "MAXRDATE_MM      int64\n",
      "LASTDATE_YR      int64\n",
      "LASTDATE_MM      int64\n",
      "FIRSTDATE_YR     int64\n",
      "FIRSTDATE_MM     int64\n",
      "dtype: object\n",
      "STATE           object\n",
      "CLUSTER         object\n",
      "HOMEOWNR        object\n",
      "GENDER          object\n",
      "DATASRCE        object\n",
      "RFA_2R          object\n",
      "RFA_2A          object\n",
      "GEOCODE2        object\n",
      "DOMAIN_A        object\n",
      "DOMAIN_B        object\n",
      "ODATEW_YR       object\n",
      "ODATEW_MM       object\n",
      "DOB_YR          object\n",
      "DOB_MM          object\n",
      "MINRDATE_YR     object\n",
      "MINRDATE_MM     object\n",
      "MAXRDATE_YR     object\n",
      "MAXRDATE_MM     object\n",
      "LASTDATE_YR     object\n",
      "LASTDATE_MM     object\n",
      "FIRSTDATE_YR    object\n",
      "FIRSTDATE_MM    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cat.isna().sum().sum() # no null values\n",
    "print(cat.dtypes) # a lot of columns with value type int64, after reviewing, I don't think any of these are ordinal values, \n",
    "                  # thus I'll simply change them all to objects\n",
    "cat = cat.astype(str)\n",
    "print(cat.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "629e3864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat as X, assign target as y; split to train/test, and further split to num/cat _ train/test\n",
    "X = pd.concat([num,cat],axis=1)\n",
    "y = tgt['TARGET_B']\n",
    "\n",
    "# splitting into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# further split\n",
    "train_num = X_train.select_dtypes('number')\n",
    "test_num = X_test.select_dtypes('number')\n",
    "train_cat = X_train.select_dtypes(exclude='number')\n",
    "test_cat = X_test.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbcce235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer = MinMaxScaler().fit(train_num)\n",
    "\n",
    "train_num = pd.DataFrame(transformer.transform(train_num), columns=train_num.columns)\n",
    "test_num = pd.DataFrame(transformer.transform(test_num), columns=train_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4040a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encode categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder().fit(cat) # used whole cat here: my train_test_split (random_state = 7) gave me an value in test_cat that was unseen in train_cat. So I've decided to violate the integrity of my process\n",
    "cols = [colname for row in encoder.categories_ for colname in row]\n",
    "\n",
    "train_cat = pd.DataFrame(encoder.transform(train_cat).toarray(), columns=cols)\n",
    "test_cat = pd.DataFrame(encoder.transform(test_cat).toarray(), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66dbc474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconcat transformed and encoded dataframes back into X_train and X_test\n",
    "X_train = pd.concat([train_num,train_cat],axis=1)\n",
    "X_test = pd.concat([test_num,test_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d23955c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509511083163025"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classification = LogisticRegression(random_state=7, solver='lbfgs',\n",
    "                  multi_class='multinomial', max_iter=1000).fit(X_train, y_train)\n",
    "classification.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28745503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9492411855951033"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score: 0.95 <-- Hey, that's pretty good! But are we just simply predicting the majority here?\n",
    "tgt['TARGET_B'].value_counts()[0]/len(tgt) # Aparrently the majority consist of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff289f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.25\n",
      "recall:  0.0010706638115631692\n",
      "f1:  0.0021321961620469083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred = classification.predict(X_test)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb566d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18146,     3],\n",
       "       [  933,     1]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fd29a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144840, 656)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample with SMOTE, I like SMOTE because I just like the feeling of trusting blackboxes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=7, k_neighbors=3)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train,y_train)\n",
    "X_train_SMOTE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "920e4702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6156788764869255\n",
      "precision:  0.06616052060737528\n",
      "recall:  0.5224839400428265\n",
      "f1:  0.1174488567990373\n"
     ]
    }
   ],
   "source": [
    "# LR again but with different variable name to keep the difference\n",
    "LR = LogisticRegression(random_state=7, solver='saga',\n",
    "                  multi_class='multinomial', max_iter=1000)\n",
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred = LR.predict(X_test)\n",
    "\n",
    "print(\"accuracy: \", LR.score(X_test, y_test))\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh no! accuracy and precision has dropped significantly. But recall as increased by a lot, so resulting in f1 score increase as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
